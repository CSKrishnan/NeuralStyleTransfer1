import tensorflow as tf
print(tf.__version__)
import IPython.display as display

import matplotlib.pyplot as plt
import matplotlib as mpl
mpl.rcParams['figure.figsize'] = (12,12)
mpl.rcParams['axes.grid'] = False

import numpy as np
import time
import functools
content_path = tf.keras.utils.get_file('belfry.jpg','https://storage.googleapis.com/khanhlvg-public.appspot.com/arbitrary-style-transfer/belfry-2611573_1280.jpg')
style_path = tf.keras.utils.get_file('style23.jpg','https://storage.googleapis.com/khanhlvg-public.appspot.com/arbitrary-style-transfer/style23.jpg')

style_predict_path = tf.keras.utils.get_file('style_predict.tflite', 'https://tfhub.dev/google/lite-model/magenta/arbitrary-image-stylization-v1-256/int8/prediction/1?lite-format=tflite')
style_transform_path = tf.keras.utils.get_file('style_transform.tflite', 'https://tfhub.dev/google/lite-model/magenta/arbitrary-image-stylization-v1-256/int8/transfer/1?lite-format=tflite')
# Function to load an image from a file, and add a batch dimension.
def load_img(path_to_img):
  img = tf.io.read_file(path_to_img)
  img = tf.io.decode_image(img, channels=3)
  img = tf.image.convert_image_dtype(img, tf.float32)
  img = img[tf.newaxis, :]

  return img

# Function to pre-process by resizing an central cropping it.
def preprocess_image(image, target_dim):
  # Resize the image so that the shorter dimension becomes 256px.
  shape = tf.cast(tf.shape(image)[1:-1], tf.float32)
  short_dim = min(shape)
  scale = target_dim / short_dim
  new_shape = tf.cast(shape * scale, tf.int32)
  image = tf.image.resize(image, new_shape)

  # Central crop the image.
  image = tf.image.resize_with_crop_or_pad(image, target_dim, target_dim)

  return image

# Load the input images.
content_image = load_img(content_path)
style_image = load_img(style_path)

# Preprocess the input images.
preprocessed_content_image = preprocess_image(content_image, 384)
preprocessed_style_image = preprocess_image(style_image, 256)

print('Style Image Shape:', preprocessed_style_image.shape)
print('Content Image Shape:', preprocessed_content_image.shape)

# Function to run style prediction on preprocessed style image.
def run_style_predict(preprocessed_style_image):
  # Load the model.
  interpreter = tf.lite.Interpreter(model_path=style_predict_path)

  # Set model input.
  interpreter.allocate_tensors()
  input_details = interpreter.get_input_details()
  interpreter.set_tensor(input_details[0]["index"], preprocessed_style_image)

  # Calculate style bottleneck.
  interpreter.invoke()
  style_bottleneck = interpreter.tensor(
      interpreter.get_output_details()[0]["index"]
      )()

  return style_bottleneck

# Calculate style bottleneck for the preprocessed style image.
style_bottleneck = run_style_predict(preprocessed_style_image)
print('Style Bottleneck Shape:', style_bottleneck.shape)

# Run style transform on preprocessed style image
def run_style_transform(style_bottleneck, preprocessed_content_image):
  # Load the model.
  interpreter = tf.lite.Interpreter(model_path=style_transform_path)

  # Set model input.
  input_details = interpreter.get_input_details()
  interpreter.allocate_tensors()

  # Set model inputs.
  interpreter.set_tensor(input_details[0]["index"], preprocessed_content_image)
  interpreter.set_tensor(input_details[1]["index"], style_bottleneck)
  interpreter.invoke()

  # Transform content image.
  stylized_image = interpreter.tensor(
      interpreter.get_output_details()[0]["index"]
      )()

  return stylized_image

stylized_image = run_style_transform(style_bottleneck, preprocessed_content_image)

                        <Card >
                            <CardImage 
                                source=
                                title={item.name}
                                style={{height:120,width:120}}
                                textStyle={{fontSize:20,fontWeight:'bold',top:60,backgroundColor:'rgba(52, 52, 52, 0.5)',textAlign:'center'}}
                            />
                        </Card>

                        '''     im = Image.open(base64.b64decode(content_image).strip())
        im.save('content.png', 'PNG')
        im = Image.open(base64.b64decode(style_image).strip())
        im.save('style.png', 'PNG') '''
'''     binary_content = a2b_base64(content_image)
        index=len(style_image)
        index-=(index%4)
        binary_style = a2b_base64(style_image[0:index])
        convert_binary_to_image('content.png', binary_content)
        convert_binary_to_image('style.png', binary_style)
        print("hi")
'''

    """
        style_image = request.form['styleImage']
        draw_image_stylized(content_image, style_image, savename='images/' + request.form['savename'])
        print("hiwdqwwqewq")
        with open('images/' + request.form['savename'], 'rb') as image_file:
            encoded_image = base64.b64encode(image_file.read()) 
        encoded_image= str('data:image/jpeg;base64,')+encoded_image.decode('utf-8')
        print("**************************************************")
        print(encoded_image) """

         /*axios.post('http://10.0.2.2:5000/baseImages', {formData})
            .then(response =>{ 
                console.log("response==== ",response);
            })
             .then(result => {
                    /* setUrlImage(result)
                setStyleImage(null)
                setStyleImageBase64(null) 
                //console.log("*******************=============",result)
                console.log("Style Transfer Complete!");
            }) 
            .catch(error => { console.log('Error-->: ',JSON.stringify(error) )
            });*/ 
         axios({
            method: 'post',
            url: 'http://10.0.2.2:5000/baseImages',
            data: formData,
            headers: {'Content-Type': 'multipart/form-data' }
            })
        .then(response => {
            console.log(JSON.stringify(response));
        })
        .catch(response => {
            console.log(JSON.stringify(response));
        }); 